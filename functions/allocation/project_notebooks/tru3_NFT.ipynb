{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import psycopg2\n",
    "import pipeline_plan_functions.utils.pipe_db_handler as dbh\n",
    "import pipeline_plan_functions.utils.data_types as dth\n",
    "from python_utils.utils.logger import logger\n",
    "import alloc_functions.feasibility_functions as ff\n",
    "import pipeline_plan_functions.utils.data_handler as dh\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import matplotlib\n",
    "import pickle\n",
    "# import plotly.graph_objects as go\n",
    "mapbox_token = ('pk.eyJ1Ijoic29mZmZ0IiwiYSI6ImNrbmZ0Z3RidzJ5NngycXA5cDNpY2c1ajIifQ.Gi2oP1Z3G5wP6pn7OF5l1A')\n",
    "FPS_COLOURS = ['#004A9C', '#45D281', '#FEC001', '#A365E0', '#5B9BD5',\n",
    "               '#FF0000', '#0563C1', '#954F72']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = (101, 102, 115, 116, 117)\n",
    "good_sites = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 17, 20, 22, 28, 13, 24]\n",
    "nft_sites = (13, 24)\n",
    "tru_spec_dict = {\n",
    "    101: 1,\n",
    "    102: 2,\n",
    "    115: 3,\n",
    "    116: 4,\n",
    "    117: 5\n",
    "}\n",
    "XPOWER = 0.98\n",
    "MAX_SHOREPOWER_HOURS = 5.38  # hours\n",
    "NEW_SHOREPOWER_HOURS = 5.5  # hours\n",
    "CHARGER_EFF = 0.9\n",
    "BATTERY_USABLE = 0.8\n",
    "DEFAULT_WAIT = 8  # HOURS\n",
    "tru_battery_kwh = [30*BATTERY_USABLE, 24*BATTERY_USABLE, 19*BATTERY_USABLE, 14*BATTERY_USABLE]\n",
    "tru_battery_dict = {'Future': 30*BATTERY_USABLE, 'Long range': 24*BATTERY_USABLE,\n",
    "                    'Medium range': 19*BATTERY_USABLE, 'Short range': 14*BATTERY_USABLE}\n",
    "tru_charger_kw = 9\n",
    "remove_charging_time = 0.5\n",
    "vehicle_specifications = ff.find_vehicle_spec(specs)\n",
    "vehicle_specifications['kwh_mile'] = 0\n",
    "vehicle_specifications['diesel_l_mile'] = 0\n",
    "elec_vehicles = vehicle_specifications['fuel_type'] == 'electric'\n",
    "diesel_vehicles = vehicle_specifications['fuel_type'] == 'diesel'\n",
    "vehicle_specifications.loc[elec_vehicles, 'kwh_mile'] = vehicle_specifications.loc[elec_vehicles, 'energy_use']\n",
    "vehicle_specifications.loc[diesel_vehicles, 'diesel_l_mile'] = vehicle_specifications.loc[diesel_vehicles, 'energy_use']\n",
    "tru_specs = ff.find_tru_spec((1, 2, 3, 4, 5))\n",
    "vehicle_specifications['tru_id'] = vehicle_specifications.index.map(tru_spec_dict)\n",
    "vehicle_specifications = vehicle_specifications.reset_index()\n",
    "vehicle_specifications = vehicle_specifications.merge(\n",
    "    tru_specs,\n",
    "    left_on='tru_id', right_on='tru_id', how='left')\n",
    "vehicle_specifications = vehicle_specifications.set_index('spec_id')\n",
    "good_specs = vehicle_specifications['vehicle_model'].to_dict()\n",
    "site_dict = ff.get_site_name_dict(2)\n",
    "\n",
    "sql_query = f\"SELECT * FROM t_vehicles WHERE client_id=2\"\n",
    "cnx = dbh.create_alch_engine()\n",
    "vehicle_df = pd.read_sql_query(sql_query, con=cnx, index_col='vehicle_id')\n",
    "vehicle_spec_dict = vehicle_df['spec_id'].to_dict()\n",
    "vehicle_ref_dict = vehicle_df['refrigerated'].to_dict()\n",
    "cnx.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = dbh.create_alch_engine()\n",
    "site_dict = ff.get_site_name_dict(2)\n",
    "sql_query = f\"SELECT * FROM t_route_master WHERE client_id = 3\"\n",
    "routes = pd.read_sql_query(sql_query, con=cnx)\n",
    "routes['spec_id'] = routes['vehicle_id'].map(vehicle_spec_dict)\n",
    "routes['refrigerated'] = routes['vehicle_id'].map(vehicle_ref_dict).astype(bool)\n",
    "routes = routes[(routes['spec_id'].isin(good_specs.keys()))\n",
    "                & routes['refrigerated']].copy()\n",
    "routes['good_site'] = ((routes['site_id_start'].isin(good_sites))\n",
    "                       & (routes['site_id_end'].isin(good_sites)))\n",
    "routes.sort_values(by=['vehicle_id', 'departure_time'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes['same_return'] = routes['site_id_start'] == routes['site_id_end']\n",
    "routes['start_right_id'] = False\n",
    "routes['duration_hours'] = (routes['arrival_time'] - routes['departure_time']).dt.total_seconds()/3600\n",
    "routes['date'] = routes['departure_time'].dt.date\n",
    "routes['start_time'] = (routes['departure_time'] - dt.datetime(2022, 1, 1)).dt.total_seconds()/3600 % 24\n",
    "routes['end_time'] = (routes['arrival_time'] - dt.datetime(2022, 1, 1)).dt.total_seconds()/3600 % 24\n",
    "routes['last_wait_onsite'] = (routes['departure_time']\n",
    "                              - routes['arrival_time'].shift(1)).dt.total_seconds()/3600\n",
    "routes['next_wait_onsite'] = (routes['departure_time'].shift(-1)\n",
    "                              - routes['arrival_time']).dt.total_seconds()/3600\n",
    "routes['week'] = routes['departure_time'].dt.isocalendar()['week']\n",
    "mask_change_veh = routes['vehicle_id'] != routes['vehicle_id'].shift(1)\n",
    "routes.loc[mask_change_veh, 'last_wait_onsite'] = 0\n",
    "mask_change_veh = routes['vehicle_id'] != routes['vehicle_id'].shift(-1)\n",
    "routes.loc[mask_change_veh, 'next_wait_onsite'] = 0\n",
    "routes.drop(columns=['payload', 'number_crates', 'client_id'], inplace=True)\n",
    "\n",
    "spec_stats = 100*routes.groupby('spec_id')[['same_return']].mean().round(3)\n",
    "spec_stats['vehicle_type'] = spec_stats.index.map(good_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_routes_per_day = routes.groupby(['spec_id', 'vehicle_id', 'date'])[['distance_miles']].count()\n",
    "avg_per_spec = count_routes_per_day.groupby('spec_id').mean()\n",
    "times_per_spec = routes.groupby('spec_id').agg({\n",
    "    'duration_hours': ['median', ff.q75, ff.q95],\n",
    "    'last_wait_onsite': ['median', ff.q25, ff.q05]})\n",
    "times_per_spec.columns = ['median_duration_hours', '75th_duration_hours', '95th_duration_hours',\n",
    "                          'median_wait_hours', '25th_wait_hours', '5th_wait_hours']\n",
    "avg_per_spec = avg_per_spec.merge(times_per_spec, left_index=True, right_index=True)\n",
    "avg_per_spec.rename(columns={'client_id': 'routes_per_day_per_vehicle'}, inplace=True)\n",
    "avg_per_spec.to_csv('sample/tru3/spec_averages.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207830\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vehicle_good_sites = routes.groupby('vehicle_id')['good_site'].mean()\n",
    "frequent_vehicles = vehicle_good_sites.loc[vehicle_good_sites > 0.6].index\n",
    "plt.hist(vehicle_good_sites, cumulative=True)\n",
    "print(len(routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['site_id_start', 'site_id_end', 'departure_time', 'arrival_time',\n",
    "       'vehicle_id', 'distance_miles', 'route_id',\n",
    "       'number_order', 'driving_time', 'duration_hours', 'date',\n",
    "       'start_time', 'end_time', 'last_wait_onsite', 'next_wait_onsite',\n",
    "       'week', 'good_site']\n",
    "# Either started from a real depot or were in another site for short time\n",
    "mask_good_start = ((routes['site_id_start'].isin(good_sites))\n",
    "                   | (routes['last_wait_onsite'] < 3))\n",
    "# Belong to a vehicle that operates mostly in the depots\n",
    "mask_good_vehicles = routes['vehicle_id'].isin(frequent_vehicles)\n",
    "mask_decent_wait = routes['next_wait_onsite'] >= 1\n",
    "mask_good_end = routes['site_id_end'].isin(good_sites)\n",
    "routes_cleaned = routes[mask_good_start & mask_good_vehicles\n",
    "                        & mask_decent_wait & mask_good_end].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183560 183464\n",
      "183464 183464\n"
     ]
    }
   ],
   "source": [
    "n_routes = len(routes_cleaned)\n",
    "new_n_routes = 0\n",
    "while n_routes != new_n_routes:\n",
    "    n_routes = len(routes_cleaned)\n",
    "    end_routes = ff.edge_routes(routes_cleaned)\n",
    "    routes_cleaned = routes_cleaned.merge(end_routes, how='left', left_on=['vehicle_id', 'departure_time'], right_on=['vehicle_id', 'date_edge'])\n",
    "    routes_cleaned['edge_routes'] = routes_cleaned['edge_routes'].fillna(False)\n",
    "    routes_cleaned = routes_cleaned[(routes_cleaned['good_site']) | (~routes_cleaned['edge_routes'])]\n",
    "    new_n_routes = len(routes_cleaned)\n",
    "    print(n_routes, new_n_routes)\n",
    "    routes_cleaned.drop(columns=['date_edge', 'edge_routes'], inplace=True)\n",
    "end_routes = ff.edge_routes(routes_cleaned)\n",
    "routes_cleaned = routes_cleaned.merge(end_routes, how='left', left_on=['vehicle_id', 'departure_time'], right_on=['vehicle_id', 'date_edge'])\n",
    "routes_cleaned['edge_routes'] = routes_cleaned['edge_routes'].fillna(False)\n",
    "routes_cleaned.drop(columns=['date_edge'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eTRU analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 'summer'\n",
    "route_kw = vehicle_specifications[f'route_power_{season}_kw'].to_dict()\n",
    "shorepower_kw = vehicle_specifications[f'shorepower_{season}_kw'].to_dict()\n",
    "\n",
    "mask_missing_wait = (routes_cleaned['edge_routes']) & (routes_cleaned['next_wait_onsite'] == 0)\n",
    "routes_cleaned.loc[mask_missing_wait, 'next_wait_onsite'] = DEFAULT_WAIT\n",
    "routes_cleaned['route_kwh'] = routes_cleaned['duration_hours'] * routes_cleaned['spec_id'].map(route_kw)\n",
    "routes_cleaned['shorepower_time'] = routes_cleaned['next_wait_onsite'].clip(upper=MAX_SHOREPOWER_HOURS)\n",
    "routes_cleaned['shorepower_kwh'] = routes_cleaned['shorepower_time'] * routes_cleaned['spec_id'].map(shorepower_kw)\n",
    "routes_cleaned['recharge_power_kw'] = (routes_cleaned['route_kwh']/CHARGER_EFF) / (routes_cleaned['next_wait_onsite'] - remove_charging_time)\n",
    "cols = ['site_id_start', 'vehicle_id', 'route_id',\n",
    "       'site_id_end', 'spec_id', 'duration_hours', 'date', 'start_time',\n",
    "       'end_time', 'next_wait_onsite', 'route_kwh', 'shorepower_time',\n",
    "       'shorepower_kwh', 'recharge_power_kw', 'battery_choice', 'edge_routes']\n",
    "routes_cleaned['battery_choice'] = 100\n",
    "for battery in tru_battery_kwh:\n",
    "    mask_feasible_battery = routes_cleaned['route_kwh'] <= battery\n",
    "    routes_cleaned.loc[mask_feasible_battery, 'battery_choice'] = battery\n",
    "routes_cleaned[cols].sort_values(by='recharge_power_kw').tail()\n",
    "pickle.dump(routes_cleaned, open('sample/tru3/routes_cleaned.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>battery_choice</th>\n",
       "      <th>Short range</th>\n",
       "      <th>Medium range</th>\n",
       "      <th>Long range</th>\n",
       "      <th>Future</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rigid 4x2</th>\n",
       "      <td>34279.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rigid 6x2</th>\n",
       "      <td>6671.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trailer 57 13.6m</th>\n",
       "      <td>98209.0</td>\n",
       "      <td>18857.0</td>\n",
       "      <td>8682.0</td>\n",
       "      <td>1443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trailer 86 13.6m</th>\n",
       "      <td>1171.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short Trailer</th>\n",
       "      <td>8318.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "battery_choice    Short range  Medium range  Long range  Future\n",
       "spec_id                                                        \n",
       "Rigid 4x2             34279.0        1259.0         0.0     0.0\n",
       "Rigid 6x2              6671.0        1077.0       451.0    12.0\n",
       "Trailer 57 13.6m      98209.0       18857.0      8682.0  1443.0\n",
       "Trailer 86 13.6m       1171.0         374.0       234.0   144.0\n",
       "Short Trailer          8318.0        1737.0       546.0     0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_feasibility = routes_cleaned.groupby(['spec_id', 'battery_choice'])['site_id_start'].count()\n",
    "route_feasibility = route_feasibility.unstack().fillna(0)\n",
    "route_feasibility.index = route_feasibility.index.map(good_specs)\n",
    "total_routes = route_feasibility.sum(axis=1).values[:, None]\n",
    "reverse_tru_bat_dict = {tru_battery_dict[key]: key for key in tru_battery_dict.keys()}\n",
    "reverse_tru_bat_dict[100] = 'Unfeasible'\n",
    "route_feasibility.columns = route_feasibility.columns.map(reverse_tru_bat_dict)\n",
    "route_feasibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create site/group allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 16:58:58|DEBUG|data_handler.py(39)|get_inputs|read inputs for run 211\n",
      "2022-08-25 16:58:58|DEBUG|controller.py(50)|get_fps_allocation_id|reading last allocation ID\n",
      "2022-08-25 16:58:59|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_allocation\n"
     ]
    }
   ],
   "source": [
    "RUN = 211\n",
    "routes_cleaned = pickle.load(open('sample/tru3/routes_cleaned.pkl', 'rb'))\n",
    "connection, cur = dbh.database_connection('test')\n",
    "nft_sites = (13, 24)\n",
    "inputs = dh.get_inputs('t_run_allocation', RUN, connection, cur)\n",
    "alloc_table = ff.create_allocation_table(inputs, nft_sites, specs, connection)\n",
    "mask_good_sites = routes_cleaned['site_id_end'].isin(nft_sites)\n",
    "route_summary = routes_cleaned.groupby(['site_id_end', 'spec_id']).agg({\n",
    "    'vehicle_id': 'nunique',\n",
    "    'route_id': 'count'\n",
    "})\n",
    "rename_dict = {\n",
    "    'vehicle_id': 'num_v',\n",
    "    'route_id': 'num_r'\n",
    "}\n",
    "route_summary.rename(columns=rename_dict, inplace=True)\n",
    "alloc_table = alloc_table.merge(\n",
    "    route_summary,\n",
    "    left_on=['site_id', 'vehicle1'], right_index=True, how='inner')\n",
    "alloc_table['xmpg'] = 0\n",
    "alloc_table['num_v_final'] = alloc_table['num_v']\n",
    "alloc_table['num_charger2'] = 0\n",
    "dbh.upload_table(alloc_table, 't_allocation')\n",
    "alloc_table.set_index('allocation_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 16:59:09|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_route_allocated\n",
      "2022-08-25 16:59:11|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_route_allocated\n",
      "2022-08-25 16:59:12|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_route_allocated\n",
      "2022-08-25 16:59:13|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_route_allocated\n",
      "2022-08-25 16:59:14|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_route_allocated\n"
     ]
    }
   ],
   "source": [
    "# iterate over all allocation IDs\n",
    "allocation_ids = alloc_table.index.values\n",
    "for idx in allocation_ids:\n",
    "# for idx in [757]:\n",
    "    # find the routes that end on the site for that specific spec id\n",
    "    mask_routes_alloc = ((routes_cleaned['site_id_end'] == alloc_table.loc[idx, 'site_id'])\n",
    "                        & (routes_cleaned['spec_id'] == alloc_table.loc[idx, 'vehicle1']))\n",
    "    cols = ['vehicle_id', 'route_id', 'spec_id', 'route_kwh', 'date', 'next_wait_onsite']\n",
    "    routes_alloc = routes_cleaned[mask_routes_alloc][cols].copy()\n",
    "    alloc_table.loc[idx, 'num_r2'] = len(routes_alloc)\n",
    "    # convert to the right table format and upload\n",
    "    rename_dict = {\n",
    "        'vehicle_id': 'allocated_vehicle_id',\n",
    "        'spec_id': 'allocated_spec_id',\n",
    "        'route_kwh': 'energy_required_kwh',\n",
    "        'next_wait_onsite': 'recharge_hours'\n",
    "    }\n",
    "    routes_alloc.rename(columns=rename_dict, inplace=True)\n",
    "    routes_alloc['allocation_id'] = idx\n",
    "    dbh.upload_table(routes_alloc, 't_route_allocated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRU shorepower profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load template shorepower\n",
    "template_shore_power = pd.read_csv(r'C:\\Users\\SofiaTaylor\\OneDrive - Flexible Power Systems Ltd\\Consulting\\SSL\\tru/template_shorepower_aug2022.csv',\n",
    "                                   usecols=['minutes', 'power_kw'], index_col='minutes')\n",
    "# Scale shore power profile to each spec based on summer average shore power requirements\n",
    "shore_profiles = {}\n",
    "for spec in vehicle_specifications.index:\n",
    "    scale_factor = (MAX_SHOREPOWER_HOURS / NEW_SHOREPOWER_HOURS) * (vehicle_specifications.loc[spec, 'shorepower_summer_kw'] / template_shore_power['power_kw'].mean())\n",
    "    shore_profiles[spec] = template_shore_power * scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 09:16:56|DEBUG|data_handler.py(39)|get_inputs|read inputs for run 211\n",
      "2022-08-26 09:17:02|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_charge_demand\n",
      "2022-08-26 09:17:02|DEBUG|feasibility_functions.py(33)|add_scenario|Added scenario 1250 to table\n",
      "2022-08-26 09:17:20|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_charge_demand\n",
      "2022-08-26 09:17:20|DEBUG|feasibility_functions.py(33)|add_scenario|Added scenario 1251 to table\n",
      "2022-08-26 09:17:24|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_charge_demand\n",
      "2022-08-26 09:17:24|DEBUG|feasibility_functions.py(33)|add_scenario|Added scenario 1252 to table\n",
      "2022-08-26 09:17:28|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_charge_demand\n",
      "2022-08-26 09:17:28|DEBUG|feasibility_functions.py(33)|add_scenario|Added scenario 1253 to table\n"
     ]
    }
   ],
   "source": [
    "SHORE_MINUTES = 5  # interval time in minutes of the shore power profile\n",
    "RUN = 212\n",
    "alloc_run = 211\n",
    "scenario_id = 1250  # Where to start the new scenarios\n",
    "\n",
    "# Get routes and allocations\n",
    "connection, cur = dbh.database_connection('test')\n",
    "\n",
    "cnx = dbh.create_alch_engine()\n",
    "sql_query = f\"select * from t_allocation where run_id={alloc_run} order by allocation_id\"\n",
    "alloc_table = pd.read_sql_query(sql_query, con=cnx, index_col='allocation_id')\n",
    "cnx.dispose()\n",
    "allocation_ids = alloc_table.index\n",
    "routes_cleaned = pickle.load(open('sample/tru3/routes_cleaned.pkl', 'rb'))\n",
    "inputs = dh.get_inputs('t_run_allocation', alloc_run, connection, cur)\n",
    "# Create a baseline HH vector covering the whole period\n",
    "start_dt = inputs['start_date']\n",
    "end_dt = inputs['end_date'] + dt.timedelta(hours=6)\n",
    "N = int((end_dt - start_dt)/dt.timedelta(minutes=SHORE_MINUTES))\n",
    "times = start_dt + np.arange(N) * dt.timedelta(minutes=SHORE_MINUTES)\n",
    "\n",
    "# calculate start/end time periods per route\n",
    "routes_cleaned['end_depot_time'] = (routes_cleaned['arrival_time']\n",
    "                                    + pd.to_timedelta(routes_cleaned['next_wait_onsite'], unit='h'))\n",
    "routes_cleaned['shorepower_time'] = routes_cleaned['next_wait_onsite'].clip(upper=NEW_SHOREPOWER_HOURS)\n",
    "routes_cleaned['start_shorepower'] = (routes_cleaned['end_depot_time']\n",
    "                                      - pd.to_timedelta(routes_cleaned['shorepower_time'], unit='h'))\n",
    "routes_cleaned['arrival_tp'] = np.round((routes_cleaned['arrival_time']-start_dt)\n",
    "                                                 /dt.timedelta(minutes=SHORE_MINUTES)).astype(int)\n",
    "routes_cleaned['start_shorepower_tp'] = np.round((routes_cleaned['start_shorepower']-start_dt)\n",
    "                                                 /dt.timedelta(minutes=SHORE_MINUTES)).astype(int)\n",
    "routes_cleaned['end_shorepower_tp'] = np.round((routes_cleaned['end_depot_time']-start_dt)\n",
    "                                                 /dt.timedelta(minutes=SHORE_MINUTES)).astype(int)\n",
    "availability_matrix = np.zeros((len(allocation_ids), N))\n",
    "onsite_matrix = np.zeros((len(allocation_ids), N))\n",
    "# iterate over allocations\n",
    "for i, idx in enumerate(allocation_ids[:]):\n",
    "    # Get the shore power value\n",
    "    indiv_profile = shore_profiles[alloc_table.loc[idx, 'vehicle1']]['power_kw'].values\n",
    "    # Create a baseline shore power profile for the allocation\n",
    "    # extract the routes for the allocation\n",
    "    mask_routes_alloc = ((routes_cleaned['site_id_end'] == alloc_table.loc[idx, 'site_id'])\n",
    "                        & (routes_cleaned['spec_id'] == alloc_table.loc[idx, 'vehicle1']))\n",
    "    cols = ['spec_id', 'start_shorepower_tp', 'end_shorepower_tp',\n",
    "            'arrival_tp', 'shorepower_kwh', 'date', 'vehicle_id']\n",
    "    routes_alloc = routes_cleaned[mask_routes_alloc][cols]\n",
    "    if len(routes_alloc) > 0:\n",
    "        allocation_shore_kw = np.zeros((len(routes_alloc), N))\n",
    "        # for each route in the allocation calculate a shorepower availability vector\n",
    "        for j, route in enumerate(routes_alloc.index[:]):\n",
    "            availability = np.zeros(N)\n",
    "            tp_arrival = routes_alloc.loc[route, 'arrival_tp']\n",
    "            tp_start = routes_alloc.loc[route, 'start_shorepower_tp']\n",
    "            tp_end = routes_alloc.loc[route, 'end_shorepower_tp']\n",
    "            availability[tp_start: tp_end] = 1\n",
    "            # add to the main allocation vector\n",
    "            availability_matrix[i] += availability\n",
    "            onsite_matrix[i, tp_arrival:tp_end] += 1\n",
    "            allocation_shore_kw[j, tp_start: tp_end] += indiv_profile[:(tp_end - tp_start)]\n",
    "        # Create a table from allocation vector and upload\n",
    "        shorepower_demand = pd.DataFrame(allocation_shore_kw.sum(axis=0),\n",
    "                                        columns=['power_demand_kw'])\n",
    "        shorepower_demand['scenario_id'] = scenario_id\n",
    "        shorepower_demand['allocated_vehicle_id'] = 0\n",
    "        shorepower_demand['datetime'] = times\n",
    "        dbh.upload_table(shorepower_demand, 't_charge_demand')\n",
    "        # Upload scenario row to scenario table\n",
    "        scenario_values = (\n",
    "            scenario_id, idx, RUN, False,\n",
    "            shorepower_demand['power_demand_kw'].sum()*SHORE_MINUTES/60,\n",
    "            9, 9, routes_alloc.groupby('date')['vehicle_id'].nunique().max(), 0)\n",
    "        scenario_id +=1\n",
    "        ff.add_scenario(scenario_values, connection,cur)\n",
    "        pickle.dump(allocation_shore_kw, open(f'sample/tru3/shorepower_profiles/shore_matrix{idx}.pkl', 'wb'))\n",
    "# cur.close()\n",
    "# connection.close()\n",
    "pickle.dump(availability_matrix, open(r'sample/tru3/shore_availability_matrix.pkl', 'wb'))\n",
    "pickle.dump(onsite_matrix, open(r'sample/tru3/onsite_availability_matrix.pkl', 'wb'))\n",
    "cur.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get charging scenarios and allocations\n",
    "alloc_run = 211\n",
    "shorepower_run = 212\n",
    "charging_run = 211\n",
    "cnx = dbh.create_alch_engine()\n",
    "sql_query = f\"select * from t_allocation where run_id={alloc_run} order by allocation_id\"\n",
    "alloc_table = pd.read_sql_query(sql_query, con=cnx, index_col='allocation_id')\n",
    "allocation_ids = alloc_table.index\n",
    "sql_query = f\"\"\"select * from t_charging_scenarios\n",
    "    where allocation_id IN {tuple(allocation_ids)}\n",
    "    and run_id IN ({charging_run}, {shorepower_run})\n",
    "    order by allocation_id, scenario_id\"\"\"\n",
    "scenarios = pd.read_sql_query(sql_query, con=cnx)\n",
    "cnx.dispose()\n",
    "\n",
    "# get availability matrix\n",
    "availability_matrix = pickle.load(open(r'sample/tru3/shore_availability_matrix.pkl', 'rb'))\n",
    "onsite_matrix = pickle.load(open(r'sample/tru3/onsite_availability_matrix.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_alloc = ['run_id', 'site_id', 'vehicle1', 'num_r', 'num_v']\n",
    "cols_scen = ['scenario_id', 'allocation_id', 'run_id', 'output_kwh',\n",
    "             'charger1']\n",
    "cols_sp = ['scenario_id', 'allocation_id', 'run_id', 'output_kwh',\n",
    "             'num_charger1']\n",
    "mask_charging = scenarios['run_id'] == charging_run\n",
    "mask_shorepower = scenarios['run_id'] == shorepower_run\n",
    "master_table = alloc_table[cols_alloc].merge(scenarios[mask_charging][cols_scen],\n",
    "                                             left_index=True, right_on='allocation_id',\n",
    "                                             how='left',\n",
    "                                             suffixes=(\"_alloc\", \"_ch\"))\n",
    "master_table = master_table.merge(scenarios[mask_shorepower][cols_sp],\n",
    "                                  left_on='allocation_id', right_on='allocation_id',\n",
    "                                  how='left',\n",
    "                                  suffixes=(\"_charging\", \"_shorepower\"))\n",
    "master_table['site_name'] = master_table['site_id'].map(site_dict)\n",
    "master_table['group'] = master_table['vehicle1'].map(good_specs)\n",
    "master_table['simult_shorepower'] = availability_matrix.max(axis=1)\n",
    "master_table.set_index('allocation_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = dbh.create_alch_engine()\n",
    "master_table['max_simultaneous_charging'] = 0\n",
    "master_table['site_simultaneous_shorepower'] = 0\n",
    "master_table['max_simult_onsite'] = 0\n",
    "# Iterate over each site\n",
    "for site in nft_sites[:]:\n",
    "    # For each site, read the charge demand tables\n",
    "    mask_site = master_table['site_id'] == site\n",
    "    site_scenarios = master_table.loc[mask_site, 'scenario_id_charging'].values\n",
    "    sql_query = f\"select datetime, power_demand_kw from t_charge_demand where scenario_id IN {dth.list_to_string(site_scenarios)}\"\n",
    "    charge_table = pd.read_sql_query(sql_query, con=cnx)\n",
    "    # Calculate how many vehicles are charging per hh\n",
    "    charge_table['charging'] = charge_table['power_demand_kw'] > 0\n",
    "    max_simultaneous_charging = charge_table.groupby('datetime')['charging'].sum().max()\n",
    "    # Add number to master table on the first allocation for the site\n",
    "    idx = master_table.loc[mask_site].index[0]\n",
    "    master_table.loc[idx, 'max_simultaneous_charging'] = max_simultaneous_charging\n",
    "    master_table.loc[idx, 'site_simultaneous_shorepower'] = availability_matrix[mask_site].sum(axis=0).max()\n",
    "    master_table.loc[idx, 'max_simult_onsite'] = onsite_matrix[mask_site].sum(axis=0).max()\n",
    "cnx.dispose()\n",
    "master_table.to_csv(r'sample/tru3/scenario_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert shore power profile to site HH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 09:36:54|DEBUG|pipe_db_handler.py(62)|upload_table|Uploaded to t_charge_demand\n",
      "2022-08-26 09:36:54|DEBUG|feasibility_functions.py(33)|add_scenario|Added scenario 1255 to table\n"
     ]
    }
   ],
   "source": [
    "scenario_id = 1255\n",
    "shorepower_hh_run = 213\n",
    "connection, cur = dbh.database_connection()\n",
    "for site in nft_sites[:]:\n",
    "    mask_site = master_table['site_id'] == site\n",
    "    sp_scenarios = master_table[mask_site]['scenario_id_shorepower'].dropna().values\n",
    "    # sp_scenarios = [1225, 1226, 1227, 1228, 1229]\n",
    "    sql_query = f\"\"\"select datetime, power_demand_kw from t_charge_demand\n",
    "        where scenario_id IN {dth.list_to_string(sp_scenarios)}\"\"\"\n",
    "    sp_table = pd.read_sql_query(sql_query, con=cnx)\n",
    "    site_sp_demand = sp_table.groupby('datetime').sum().reset_index()\n",
    "    site_sp_demand['hh_period'] = (\n",
    "        (site_sp_demand['datetime'] -  site_sp_demand['datetime'].min())\n",
    "        / dt.timedelta(hours=0.5)).astype(int)\n",
    "    site_sp_hh_demand = site_sp_demand.groupby('hh_period').agg({\n",
    "        'datetime': 'min',\n",
    "        'power_demand_kw': 'max'\n",
    "        })\n",
    "    site_sp_hh_demand['scenario_id'] = scenario_id\n",
    "    site_sp_hh_demand['allocated_vehicle_id'] = 0\n",
    "    dbh.upload_table(site_sp_hh_demand, 't_charge_demand')\n",
    "    # Upload scenario row to scenario table\n",
    "    first_allocation = scenarios[scenarios['scenario_id'].isin(sp_scenarios)]['allocation_id'].min()\n",
    "    combined_output = scenarios[scenarios['scenario_id'].isin(sp_scenarios)]['output_kwh'].sum()\n",
    "    combined_vehicles = scenarios[scenarios['scenario_id'].isin(sp_scenarios)]['num_charger1'].sum()\n",
    "    scenario_values = (\n",
    "        scenario_id, first_allocation, shorepower_hh_run, False,\n",
    "        combined_output,\n",
    "        9, 9, combined_vehicles, 0)\n",
    "    scenario_id +=1\n",
    "    ff.add_scenario(scenario_values, connection, cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make scenario master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a master scenario table with\n",
    "# charging scenario, peak shore power and combined shore power\n",
    "scenario_dict = {\n",
    "    211: 'Charging',\n",
    "    212: 'Shorepower',\n",
    "    213: 'Shorepower combined'\n",
    "}\n",
    "allocation_ids = alloc_table.index\n",
    "sql_query = f\"\"\"select scenario_id, allocation_id, run_id from t_charging_scenarios\n",
    "    where allocation_id IN {tuple(allocation_ids)}\n",
    "    and run_id IN (211, 212, 213) order by allocation_id, scenario_id\"\"\"\n",
    "scenarios = pd.read_sql_query(sql_query, con=cnx)\n",
    "scenarios.set_index(['allocation_id', 'run_id'], inplace=True)\n",
    "scenarios.sort_values(by='allocation_id', inplace=True)\n",
    "scenarios = scenarios.unstack()\n",
    "scenarios.columns = scenarios.columns.droplevel()\n",
    "scenarios = scenarios.merge(alloc_table[['site_id', 'vehicle1']],\n",
    "                left_index=True, right_index=True, how='left')\n",
    "scenarios['site_name'] = scenarios['site_id'].map(site_dict)\n",
    "scenarios.rename(columns=scenario_dict, inplace=True)\n",
    "scenarios['group'] = scenarios['vehicle1'].map(good_specs)\n",
    "scenarios.to_csv('sample/tru3/scenario_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Max demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [1246, 1247, 1248, 1249, 1254, 1255]\n",
    "cnx = dbh.create_alch_engine()\n",
    "sql_query = f\"\"\"select datetime, power_demand_kw,scenario_id from t_charge_demand\n",
    "    where scenario_id IN {dth.list_to_string(scenarios)}\"\"\"\n",
    "demand_table = pd.read_sql_query(sql_query, con=cnx)\n",
    "cnx.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>power_demand_kw</th>\n",
       "      <th>scenario_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">13</th>\n",
       "      <th>2022-02-12 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12 01:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th>2022-05-01 03:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01 04:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01 05:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01 05:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7512 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          power_demand_kw  scenario_id\n",
       "site datetime                                         \n",
       "13   2022-02-12 00:00:00              0.0            1\n",
       "     2022-02-12 00:30:00              0.0            1\n",
       "     2022-02-12 01:00:00              0.0            1\n",
       "     2022-02-12 01:30:00              0.0            1\n",
       "     2022-02-12 02:00:00              0.0            1\n",
       "...                                   ...          ...\n",
       "24   2022-05-01 03:30:00              0.0            2\n",
       "     2022-05-01 04:00:00              0.0            2\n",
       "     2022-05-01 04:30:00              0.0            2\n",
       "     2022-05-01 05:00:00              0.0            2\n",
       "     2022-05-01 05:30:00              0.0            2\n",
       "\n",
       "[7512 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_site = {\n",
    "    1246: 13,\n",
    "    1247: 13,\n",
    "    1254: 13,\n",
    "    1248: 24,\n",
    "    1249: 24,\n",
    "    1255: 24\n",
    "}\n",
    "demand_table['site'] = demand_table['scenario_id'].map(scenario_site)\n",
    "site_demand = demand_table.groupby(['site', 'datetime']).agg({\n",
    "    'power_demand_kw': 'sum',\n",
    "    'scenario_id': 'nunique'\n",
    "})\n",
    "site_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_demand_kw</th>\n",
       "      <th>scenario_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>266.663723</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>62.920538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      power_demand_kw  scenario_id\n",
       "site                              \n",
       "13         266.663723            3\n",
       "24          62.920538            3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_demand.groupby('site').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get number of TRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spec_id\n",
       "101     345\n",
       "102      86\n",
       "115    1513\n",
       "116      19\n",
       "117     177\n",
       "Name: vehicle_id, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_cleaned2 = pickle.load(open('sample/tru2/routes_cleaned_new.pkl', 'rb'))\n",
    "routes_cleaned2.groupby('spec_id')['vehicle_id'].nunique()\n",
    "print(routes_cleaned2['vehicle_id'].unique().shape)\n",
    "print(routes_cleaned['vehicle_id'].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle list already included\n",
    "vehicles_old = routes_cleaned2['vehicle_id'].unique()\n",
    "# Get vehicles operating in the new sites\n",
    "vehicles_nft = routes_cleaned[routes_cleaned['site_id_end'].isin(nft_sites)]['vehicle_id'].unique()\n",
    "# Find how many of these weren't included before\n",
    "new_vehicles = [v for v in vehicles_nft if v not in vehicles_old]\n",
    "# Check that they're regular/large trailers\n",
    "# Export final vehicle count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vehicles = routes_cleaned.groupby('spec_id')[['vehicle_id']].nunique()\n",
    "n_vehicles['group'] = n_vehicles.index.map(good_specs)\n",
    "n_vehicles.to_csv('sample/tru3/n_vehicles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count simultaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_cleaned = pickle.load(open('sample/tru3/routes_cleaned.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_veh = routes_cleaned.groupby('site_id_end')[['vehicle_id']].nunique() \n",
    "n_veh['site_name']= n_veh.index.map(site_dict)\n",
    "departures = routes_cleaned.groupby(['site_id_start', 'date'])['route_id'].count().groupby('site_id_start').max()\n",
    "n_veh.merge(departures, left_index=True, right_index=True, how='left').to_csv('sample/tru3/count_veh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_cleaned = pickle.load(open('sample/tru2/routes_cleaned_new.pkl', 'rb'))\n",
    "site_arrivals = routes_cleaned[routes_cleaned['site_id_end'].isin(good_sites)]\n",
    "weekly_usage = site_arrivals.groupby(['week']).agg({\n",
    "    'route_kwh': 'sum',\n",
    "    'shorepower_kwh': 'sum',\n",
    "    'route_id': 'count',\n",
    "    'vehicle_id': 'nunique'})\n",
    "weekly_usage['total_kwh_tru'] = weekly_usage['route_kwh']*0.72753923 + weekly_usage['shorepower_kwh']*0.639393939\n",
    "weekly_usage.columns = ['route_kwh', 'shorepower_kwh', 'n_routes', 'n_vehicles', 'total_kwh_tru']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_cleaned_nft = pickle.load(open('sample/tru3/routes_cleaned.pkl', 'rb'))\n",
    "site_arrivals = routes_cleaned_nft[routes_cleaned_nft['site_id_end'].isin(good_sites)]\n",
    "weekly_usage_nft = site_arrivals.groupby(['week']).agg({\n",
    "    'route_kwh': 'sum',\n",
    "    'shorepower_kwh': 'sum',\n",
    "    'route_id': 'count',\n",
    "    'vehicle_id': 'nunique'})\n",
    "weekly_usage_nft['total_kwh_tru'] = weekly_usage_nft['route_kwh']*0.72753923 + weekly_usage_nft['shorepower_kwh']*0.639393939\n",
    "weekly_usage_nft.columns = ['route_kwh', 'shorepower_kwh', 'n_routes', 'n_vehicles', 'total_kwh_tru']\n",
    "weekly_usage_nft.to_csv('sample/tru3/weekly_energy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_kwh</th>\n",
       "      <th>shorepower_kwh</th>\n",
       "      <th>n_routes</th>\n",
       "      <th>n_vehicles</th>\n",
       "      <th>total_kwh_tru</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20093.305383</td>\n",
       "      <td>43859.560944</td>\n",
       "      <td>2674</td>\n",
       "      <td>1492</td>\n",
       "      <td>42662.205362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128398.950136</td>\n",
       "      <td>274393.466403</td>\n",
       "      <td>16766</td>\n",
       "      <td>1989</td>\n",
       "      <td>268860.792634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>119662.548403</td>\n",
       "      <td>250839.791514</td>\n",
       "      <td>15608</td>\n",
       "      <td>1964</td>\n",
       "      <td>247444.640679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>121759.244936</td>\n",
       "      <td>254730.772333</td>\n",
       "      <td>15889</td>\n",
       "      <td>1928</td>\n",
       "      <td>251457.939213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>121023.189853</td>\n",
       "      <td>253980.178306</td>\n",
       "      <td>15763</td>\n",
       "      <td>1940</td>\n",
       "      <td>250442.504992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>125402.192019</td>\n",
       "      <td>267651.229211</td>\n",
       "      <td>16460</td>\n",
       "      <td>2014</td>\n",
       "      <td>262369.587946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>134757.080283</td>\n",
       "      <td>286152.548875</td>\n",
       "      <td>17714</td>\n",
       "      <td>2041</td>\n",
       "      <td>281005.267806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>136915.802156</td>\n",
       "      <td>287791.430458</td>\n",
       "      <td>17666</td>\n",
       "      <td>2043</td>\n",
       "      <td>283623.713606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>135273.695339</td>\n",
       "      <td>282999.259881</td>\n",
       "      <td>17460</td>\n",
       "      <td>2032</td>\n",
       "      <td>279364.931655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>131911.215681</td>\n",
       "      <td>274889.541625</td>\n",
       "      <td>17156</td>\n",
       "      <td>2066</td>\n",
       "      <td>271733.291094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>132867.961719</td>\n",
       "      <td>282445.001600</td>\n",
       "      <td>17215</td>\n",
       "      <td>2049</td>\n",
       "      <td>277260.276685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100148.849475</td>\n",
       "      <td>210656.126128</td>\n",
       "      <td>13093</td>\n",
       "      <td>1998</td>\n",
       "      <td>207554.467092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          route_kwh  shorepower_kwh  n_routes  n_vehicles  total_kwh_tru\n",
       "week                                                                    \n",
       "6      20093.305383    43859.560944      2674        1492   42662.205362\n",
       "7     128398.950136   274393.466403     16766        1989  268860.792634\n",
       "8     119662.548403   250839.791514     15608        1964  247444.640679\n",
       "9     121759.244936   254730.772333     15889        1928  251457.939213\n",
       "10    121023.189853   253980.178306     15763        1940  250442.504992\n",
       "11    125402.192019   267651.229211     16460        2014  262369.587946\n",
       "12    134757.080283   286152.548875     17714        2041  281005.267806\n",
       "13    136915.802156   287791.430458     17666        2043  283623.713606\n",
       "14    135273.695339   282999.259881     17460        2032  279364.931655\n",
       "15    131911.215681   274889.541625     17156        2066  271733.291094\n",
       "16    132867.961719   282445.001600     17215        2049  277260.276685\n",
       "17    100148.849475   210656.126128     13093        1998  207554.467092"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_usage_nft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(weekly_usage_nft + weekly_usage).to_csv('sample/tru3/weekly_energy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_hours    8.285317e+05\n",
       "distance_miles    1.091079e+07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes[['duration_hours', 'distance_miles']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_hours     31554.823611\n",
       "distance_miles    644230.577999\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_arrivals[['duration_hours', 'distance_miles']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_hours    6.827636e+05\n",
       "distance_miles    8.537731e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_cleaned[['duration_hours', 'distance_miles']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_hours    0.824065\n",
       "distance_miles    0.782503\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_cleaned[['duration_hours', 'distance_miles']].sum() / routes[['duration_hours', 'distance_miles']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration_hours    0.862150\n",
       "distance_miles    0.841548\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((routes_cleaned[['duration_hours', 'distance_miles']].sum() + site_arrivals[['duration_hours', 'distance_miles']].sum())\n",
    " / routes[['duration_hours', 'distance_miles']].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c70d8ca8a9326c117f3cbb1600d40e4646a06cd0d6560aa3efc7e3f56e409b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pipetel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
